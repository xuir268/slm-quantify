model_id: Qwen/Qwen2-1.5B-Instruct
use_qlora: false
seq_len: 512
batch_size: 2
eval_batch_size: 2
grad_accum: 4
epochs: 1
max_steps: 1000
eval_strategy: "no"
save_strategy: "epoch"
output_dir: results/models/qwen15b_lora
lora: { r: 16, alpha: 32, dropout: 0.05, target_modules: ["q_proj","k_proj","v_proj","o_proj"] }
data: { train: data/processed/train.jsonl, dev: data/processed/dev.jsonl }